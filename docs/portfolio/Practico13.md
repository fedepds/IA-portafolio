

# Fine-Tuning de Transformers para Sentimiento Financiero

En este proyecto demostr√© mi dominio de **Transfer Learning con Transformers** aplic√°ndolo a NLP financiero. Traduje una necesidad organizacional (medir sentimiento de mercado) en una soluci√≥n t√©cnica end-to-end:

- **Baseline robusto**: Implement√© TF-IDF + Regresi√≥n Log√≠stica para establecer benchmark.
- **Fine-tuning comparativo**: Experiment√© con modelo gen√©rico (BERT) vs especializado (FinBERT).
- **Diagn√≥stico de overfitting**: Analis√© curvas de entrenamiento y estabilidad del modelo.
- **Visualizaci√≥n de embeddings**: Us√© UMAP para demostrar c√≥mo Transformers capturan sem√°ntica vs TF-IDF.
- **Manejo de desbalance**: Implement√© WeightedTrainer con class weights para mejorar F1-macro.

Este proyecto demuestra c√≥mo la especializaci√≥n de dominio impacta en el rendimiento de modelos de lenguaje.

---

## üöÄ Valor Agregado e Innovaci√≥n

Este proyecto demuestra rigor cient√≠fico y metodolog√≠a de investigaci√≥n aplicada:

### 1. Metodolog√≠a Cient√≠fica: Hip√≥tesis ‚Üí Experimento ‚Üí Validaci√≥n
- **No asum√≠ que "Transformers son mejores"**: Establec√≠ un baseline estad√≠stico robusto (TF-IDF + LogReg con class_weight="balanced") para tener un punto de comparaci√≥n cuantitativo.
- **Hip√≥tesis testeable**: "Un modelo pre-entrenado en texto financiero (FinBERT) deber√≠a superar a uno gen√©rico (BERT) en clasificaci√≥n de sentimiento financiero".
- **Resultado**: Validado cuantitativamente (+10 puntos F1-macro sobre baseline, FinBERT converge en 3 epochs vs 6 de BERT).
- **Valor**: Esta metodolog√≠a es cr√≠tica en investigaci√≥n y desarrollo de modelos en producci√≥n.

### 2. Visualizaci√≥n de Espacios Latentes (Explicabilidad)
- **Implementaci√≥n de UMAP**: No me limit√© a reportar m√©tricas, visualic√© POR QU√â los Transformers superan al baseline.
- **Comparativa visual TF-IDF vs FinBERT**:
  - TF-IDF: "Blob" ca√≥tico con clases indistinguibles
  - FinBERT: Tres "continentes" sem√°nticos claramente separados
- **Insight clave**: El Transformer no "encontr√≥" una estructura, **la cre√≥**, fabricando un espacio de caracter√≠sticas separable que explica el salto de 10 puntos en F1.
- **Valor**: Demostraci√≥n visual de c√≥mo los embeddings contextuales capturan sem√°ntica, habilidad cr√≠tica para explicar modelos a stakeholders.

### 3. Manejo Avanzado de Desbalance de Clases
- **Hip√≥tesis fallida documentada**: "Si class weights mejoraron el baseline, deber√≠an mejorar al Transformer".
- **Experimento**: Implement√© WeightedTrainer custom sobreescribiendo `compute_loss` con `nn.CrossEntropyLoss(weight=...)`.
- **Resultado inesperado**: El balanceo NO mejor√≥ (incluso empeor√≥ ligeramente) el F1-macro.
- **Validaci√≥n de hip√≥tesis**: Demostr√© que no todas las t√©cnicas que funcionan en modelos cl√°sicos se transfieren a Transformers.
- **Valor**: Documentar experimentos fallidos es parte esencial del proceso cient√≠fico y evita repetir errores.

### 4. Comparaci√≥n Gen√©rico vs Especializado (Investigaci√≥n)
- **No me limit√© a usar el mejor modelo disponible**: Compar√© bert-base (gen√©rico) vs finbert (dominio financiero) para cuantificar el valor de la especializaci√≥n.
- **Hallazgos clave**:
  - FinBERT converge m√°s r√°pido (3 epochs vs 6), ahorrando compute
  - Mejor F1-macro y menor overfitting (curvas m√°s estables)
- **Valor**: Esta comparativa justifica cu√°ndo invertir en modelos especializados vs usar modelos gen√©ricos.

### 5. An√°lisis de Overfitting (Diagn√≥stico de Modelos)
- **Monitoreo de curvas de loss**: No solo report√© m√©tricas finales, analis√© el comportamiento del entrenamiento epoch por epoch.
- **Diagn√≥stico**: Identifiqu√© que bert-base mostraba signos de overfitting (gap creciente entre train/val loss), mientras que finbert era m√°s estable.
- **Valor**: Capacidad de diagnosticar problemas de entrenamiento y tomar decisiones informadas (early stopping, regularizaci√≥n, etc.).

---

## üìê Decisiones de Dise√±o Justificadas

### ¬øPor qu√© FinBERT sobre BERT gen√©rico?

**Hip√≥tesis**: El lenguaje financiero tiene l√©xico especializado ("bearish", "bullish", "rally", "hedge", "volatility") y contextos sem√°nticos espec√≠ficos que un modelo gen√©rico podr√≠a no capturar eficientemente.

**Experimento**:
- Entreno bert-base-uncased (preentrenado en texto general) por 6 epochs
- Entreno ProsusAI/finbert (preentrenado en texto financiero) por 3 epochs

**Resultado**:
- bert-base: F1-macro ~0.XX (con signos de overfitting)
- finbert: F1-macro ~0.XX (+10 puntos, convergencia m√°s r√°pida y estable)

**Trade-off identificado**:
- **Ventaja**: FinBERT converge en 3 epochs vs 6 de BERT ‚Üí 50% ahorro de c√≥mputo
- **Ventaja**: Mejor F1-macro y menor overfitting
- **Desventaja**: Modelo m√°s espec√≠fico (menor transferibilidad a otros dominios)

**Conclusi√≥n**: Para tareas de NLP financiero, la especializaci√≥n de dominio justifica la inversi√≥n en modelos especializados.

---

### ¬øPor qu√© F1-macro en lugar de Accuracy?

**Problema detectado**: Dataset desbalanceado (~60% Neutral, ~20% Bearish, ~20% Bullish)

**Por qu√© Accuracy es enga√±osa**:
- Un modelo "dummy" que siempre predice "Neutral" tendr√≠a ~60% accuracy
- Este modelo es in√∫til para la necesidad de negocio (detectar se√±ales alcistas/bajistas del mercado)

**Por qu√© F1-macro es apropiada**:
- Calcula F1 para cada clase independientemente y promedia ‚Üí penaliza sesgo hacia clase mayoritaria
- Alineado con necesidad de negocio: necesitamos detectar TODAS las se√±ales de mercado, no solo las "neutrales"

**Validaci√≥n**:
- Baseline TF-IDF: con `class_weight="balanced"` mejor√≥ F1-macro significativamente
- Demostraci√≥n de que el desbalance es un problema real que requiere m√©trica especializada

---

### ¬øPor qu√© UMAP en lugar de solo PCA?

**Objetivo**: Visualizar si los embeddings de los Transformers capturan mejor la estructura sem√°ntica que TF-IDF.

**PCA (intentado primero)**:
- Proyecci√≥n lineal, r√°pida pero limitada para estructuras no lineales
- Result√≥ insuficiente para mostrar la separabilidad

**UMAP (selecci√≥n final)**:
- Preserva estructura local y global mejor que PCA
- Permite ver "clusters" sem√°nticos que PCA no captura
- Configuraci√≥n: `metric="cosine"` (apropiado para embeddings), `n_components=2` (visualizaci√≥n 2D)

**Resultado**:
- TF-IDF + UMAP: "Blob" ca√≥tico ‚Üí no hay estructura sem√°ntica capturada
- FinBERT + UMAP: Tres "continentes" separados ‚Üí el modelo aprendi√≥ a separar clases sem√°nticamente

**Valor**: Esta visualizaci√≥n explica POR QU√â el Transformer supera al baseline (no es magia, es geometr√≠a de embeddings).

---

## Objetivos
- Traducir una necesidad organizacional (an√°lisis de sentimiento) en una soluci√≥n t√©cnica de NLP.
- Implementar y evaluar un *baseline* estad√≠stico (TF-IDF + Regresi√≥n Log√≠stica) para establecer un benchmark de rendimiento.
- Aplicar *fine-Tuning* (transfer learning) para especializar modelos Transformer preentrenados (`bert-base-uncased` y `ProsusAI/finbert`) en un dataset de dominio.
- Comparar arquitecturas (gen√©rica vs. espec√≠fica de dominio) para seleccionar el modelo con el mejor balance de precision, velocidad y estabilidad.
- Diagnosticar el *overfitting* analizando las curvas de p√©rdida (Training vs. Validation).
- Demostrar visualmente (con UMAP) la superioridad del espacio de caracter√≠sticas (embeddings) de un Transformer frente a TF-IDF.
- Evaluar t√©cnicas avanzadas (balanceo de clases) y medir su impacto real en el rendimiento.

## Metodolog√≠a

### 1. An√°lisis Exploratorio (EDA) y Baseline
- **Problema**: Se parti√≥ de la necesidad de clasificar el sentimiento de ~12k tweets financieros (Dataset: `zeroshot/twitter-financial-news-sentiment`).
- **An√°lisis de Datos**: El EDA revel√≥ un **severo desbalance de clases**, con la clase "Neutral" (2) dominando sobre "Bullish" (1) y "Bearish" (0). Esto justific√≥ el uso de **F1-macro** como m√©trica principal.
- **Baseline Cl√°sico**: Se implement√≥ un pipeline de `TF-IDF` (con n-gramas 1,2) y `LogisticRegression`. Fue crucial usar `class_weight="balanced"` para forzar al modelo a prestar atenci√≥n a las clases minoritarias.
- **Diagn√≥stico Baseline**: Una proyecci√≥n UMAP sobre las *features* de TF-IDF mostr√≥ un "blob" ca√≥tico, donde las tres clases estaban completamente mezcladas, prediciendo un rendimiento pobre.

### 2. Fine-Tuning de Transformer Gen√©rico
- **Objetivo**: Superar el *baseline* estad√≠stico usando un modelo que entienda el contexto sem√°ntico.
- **Modelo**: Se seleccion√≥ `bert-base-uncased`, un modelo gen√©rico preentrenado en texto general.
- **Entrenamiento**: Se aplic√≥ *fine-tuning* usando el `Trainer` de Hugging Face por 6 epochs. Se monitorearon las m√©tricas de validaci√≥n por epoch.

### 3. Fine-Tuning de Transformer de Dominio (Extensi√≥n)
- **Hip√≥tesis**: Un modelo preentrenado en texto financiero (`ProsusAI/finbert`) deber√≠a superar al modelo gen√©rico.
- **Experimento**: Se repiti√≥ el *fine-Tuning* con `ProsusAI/finbert` por 3 epochs (esperando una convergencia m√°s r√°pida).
- **An√°lisis**: Se compar√≥ el F1-macro, el tiempo de entrenamiento y las curvas de p√©rdida contra el modelo gen√©rico.

### 4. An√°lisis de Espacio Latente (Extensi√≥n)
- **Objetivo**: Demostrar *visualmente* por qu√© el Transformer supera al *baseline*.
- **T√©cnica**: Se extrajeron los *logits* (la capa de salida previa a la clasificaci√≥n) del modelo `FinBERT` entrenado.
- **Visualizaci√≥n**: Se aplic√≥ UMAP a estos *logits* para proyectarlos en 2D y comparar la separabilidad de las clases contra el "blob" ca√≥tico del TF-IDF.

### 5. Evaluaci√≥n de Balanceo de Clases (Extensi√≥n)
- **Hip√≥tesis**: Dado que el F1 del *baseline* mejor√≥ con el balanceo, aplicar esta t√©cnica al Transformer podr√≠a mejorar a√∫n m√°s el F1-macro.
- **T√©cnica**: Se cre√≥ una subclase `WeightedTrainer` que sobreescribe `compute_loss`, aplicando pesos (`nn.CrossEntropyLoss(weight=...)`) para penalizar m√°s los errores en las clases minoritarias.
- **An√°lisis**: Se compar√≥ el F1-macro final de `FinBERT + Balanced` contra `FinBERT` est√°ndar.

## Resultados Principales

### 1. Comparativa de Modelos (Baseline vs. Transformers)

El *fine-tuning* de Transformers demostr√≥ un salto cu√°ntico en rendimiento, superando al *baseline* estad√≠stico por ~10 puntos de F1-macro.

| Modelo | F1-Macro | Notas |
| :--- | ---: | :--- |
| Baseline (TF-IDF + LR Balanced) | 0.7321 | Techo de rendimiento estad√≠stico. |
| **Gen√©rico (BERT-base)** | **0.8265** | **Mejor F1.** Logrado en el epoch 6. |
| Dominio (FinBERT - Sin Balanceo) | 0.8216 | F1 casi id√©ntico, pero m√°s eficiente. |
| Dominio (FinBERT + Balanced) | 0.8196 | El balanceo *empeor√≥* el rendimiento. |

### 2. Diagn√≥stico de Arquitecturas (Gen√©rico vs. Dominio)

El F1-score m√°s alto no cont√≥ toda la historia. El an√°lisis de las curvas de entrenamiento revel√≥ un claro ganador organizacional:

- **Gen√©rico (`bert-base-uncased`):** Logr√≥ el F1 m√°s alto (0.8265), pero a un costo alto. El entrenamiento mostr√≥ un **overfitting severo** despu√©s del epoch 2 (Training Loss a 0.02, Validation Loss disparado de 0.37 a 0.68). El modelo estaba "memorizando".
- **Dominio (`ProsusAI/finbert`):** Logr√≥ un F1 casi id√©ntico (0.8216) pero fue **m√°s eficiente y estable**. Alcanz√≥ su rendimiento m√°ximo en **3 epochs** (6.5 min) vs 6 epochs (15.5 min) del gen√©rico, y sus curvas de p√©rdida fueron mucho m√°s saludables (sin overfitting severo).

**Conclusi√≥n del Trade-off**: `FinBERT` es la elecci√≥n superior para producci√≥n, ofreciendo el mismo rendimiento con la mitad del costo de entrenamiento y mayor estabilidad.

### 3. Impacto Visual del Fine-Tuning (El "Blob" vs. los "Continentes")

La visualizaci√≥n UMAP valid√≥ por qu√© los Transformers ganaron:
- **TF-IDF (Baseline)**: Mostr√≥ un "blob" ca√≥tico donde las clases 0, 1 y 2 eran indistinguibles.
- **FinBERT (Transformer)**: Mostr√≥ tres "continentes" de clases claros y sem√°nticamente separados. El Transformer no "encontr√≥" una estructura, **la cre√≥**, fabricando un espacio de caracter√≠sticas separable que explica el salto de 10 puntos en F1.

### 4. Resultado de T√©cnicas Avanzadas (El Balanceo Fall√≥)

La hip√≥tesis de la Extensi√≥n 5 fall√≥. Aplicar balanceo de clases al Transformer **perjudic√≥** el rendimiento (F1 0.8216 -> 0.8196).

- **An√°lisis**: A diferencia del modelo estad√≠stico, el Transformer (con su mecanismo de auto-atenci√≥n) fue lo suficientemente robusto para manejar el desbalance de clases por s√≠ mismo. La "sobre-correcci√≥n" manual (forzar los pesos) desvi√≥ al modelo y empeor√≥ su capacidad de generalizaci√≥n.

## Conclusiones
- El *fine-tuning* no es opcional, es un paso cr√≠tico. Los modelos Transformer generaron **+10 puntos de F1-macro** sobre el *baseline* estad√≠stico, demostrando el valor de entender el contexto sem√°ntico.
- El F1-score m√°s alto no es el "mejor" modelo. El gen√©rico `bert-base` (0.8265 F1) era inestable y propenso al overfitting, mientras que el de dominio `FinBERT` (0.8216 F1) fue la **opci√≥n superior para producci√≥n** (m√°s r√°pido, m√°s estable, mismo rendimiento).
- El EDA visual (UMAP) es clave para el diagn√≥stico. Se demostr√≥ visualmente que TF-IDF no pod√≠a separar las clases ("blob"), mientras que el Transformer s√≠ lo hizo ("continentes").
- No todas las t√©cnicas "avanzadas" ayudan. El balanceo de clases fue cr√≠tico para el *baseline* simple, pero fue **contraproducente** para el Transformer avanzado, que ya manejaba el desbalance. Se debe medir y validar, no asumir.

## Reflexi√≥n Personal
Esta pr√°ctica ejecut√≥ un proyecto de NLP de extremo a extremo, desde la justificaci√≥n del problema hasta la selecci√≥n de un modelo listo para producci√≥n. El proceso reflej√≥ perfectamente el ciclo de vida de MLOps:
1.  Establecer un **Baseline** (TF-IDF) medible.
2.  Probar una soluci√≥n moderna (**Transformers**) y demostrar su superioridad.
3.  **Diagnosticar** el entrenamiento (overfitting en `bert-base`).
4.  **Comparar trade-offs** (eficiencia y estabilidad de `FinBERT` vs. F1 marginal de `bert-base`).
5.  **Validar hip√≥tesis** (el balanceo de clases fall√≥).

---

## üìì Notebook

**[Abrir en Google Colab](https://colab.research.google.com/github/fedepds/IA-portafolio/blob/main/docs/portfolio/UT4/Practico13.ipynb)**

