# LangChain: Prompting y Salida Estructurada con OpenAI

En este proyecto domin茅 **LangChain**, el framework esencial para construir aplicaciones LLM de producci贸n. Demostr茅 mis habilidades en:

- **Ingenier铆a de prompts**: Dise帽o de plantillas reutilizables con ChatPromptTemplate y LCEL (`|`).
- **Salida estructurada**: Transformaci贸n de respuestas LLM en objetos Python validados (Pydantic).
- **Observabilidad**: Medici贸n de tokens y latencia con LangSmith para optimizar costos.
- **Few-shot learning**: Comparaci贸n emp铆rica vs zero-shot y an谩lisis del impacto de temperatura.
- **Map-Reduce**: Procesamiento de textos largos que exceden la ventana de contexto.
- **RAG b谩sico**: Implementaci贸n de Retrieval-Augmented Generation con FAISS para chatbot de soporte.

Este proyecto refleja el toolkit completo para construir aplicaciones LLM robustas, observables y estructuradas.

## Objetivos
- Instanciar un modelo de chat de OpenAI (`ChatOpenAI`) y controlar par谩metros de decodificaci贸n (`temperature`, `max_tokens`).
- Dise帽ar prompts reutilizables con `ChatPromptTemplate` y encadenar componentes usando LangChain Expression Language (LCEL).
- Forzar y garantizar salidas estructuradas (JSON) que adhieran a un esquema `Pydantic` usando `with_structured_output`.
- Utilizar `LangSmith` para medir m茅tricas clave (tokens y latencia) y entender la observabilidad de la cadena.
- Comparar el rendimiento y formato de `zero-shot` vs. `few-shot prompting` y analizar el impacto de la temperatura en ambos.
- Implementar un patr贸n de `Map-Reduce` para procesar textos que exceden la ventana de contexto.
- Construir un pipeline de RAG b谩sico para "aterrizar" (ground) las respuestas del modelo en una base de conocimiento local (FAISS).

## Metodolog铆a

### 1. Control de Par谩metros de Decodificaci贸n
- **Problema**: Se analiz贸 el efecto de `temperature` en la generaci贸n.
- **T茅cnica**: Se invoc贸 a `ChatOpenAI` con `temperature=0.0` (determinista) y `temperature=0.9` (creativo) (Parte 1).
- **Diagn贸stico**: Se observ贸 que la temperatura solo afecta a **tareas abiertas** (creativas, como el tuit) y no a **tareas factuales** (como la identidad del modelo), donde la respuesta es casi id茅ntica independientemente del par谩metro.

### 2. Plantillas y Encadenamiento (LCEL)
- **Objetivo**: Separar la l贸gica de la instrucci贸n (`prompt`) de los datos (`variables`).
- **T茅cnica**: Se reemplazaron los strings de prompt por `ChatPromptTemplate` y se encaden贸 con el LLM usando el operador `|` (LCEL) (Parte 2).
- **An谩lisis (Zero-shot vs. Few-shot)**: Se compararon los patrones (Parte 6). Se descubri贸 que un `temperature > 0` pod铆a **romper la precisi贸n** de un modelo *few-shot* si los ejemplos proporcionados estaban incompletos (ej. faltaba la clase `NEU`).

### 3. Garant铆a de Salida Estructurada (El "Contrato")
- **Hip贸tesis**: "Pedir" un JSON mediante un prompt es fr谩gil; se debe "forzar" un JSON mediante un esquema.
- **T茅cnica**: Se defini贸 un esquema `Pydantic` (ej. `Traduccion`, `Resumen`, `ExtractInfo`) y se vincul贸 al modelo usando `llm.with_structured_output(...)` (Parte 3, 5, 8).
- **Resultado**: Esto elimin贸 la necesidad de parsear strings, proporcionando un **objeto Python nativo** fiable como salida.

### 4. Observabilidad (Costos y Velocidad)
- **Objetivo**: Medir el rendimiento de la cadena.
- **T茅cnica**: Se utiliz贸 `LangSmith` (activado en Parte 0) para inspeccionar las trazas de ejecuci贸n (Parte 4).
- **An谩lisis**: Se midi贸 la `latencia` (velocidad) y el `uso de tokens` (costo) de cada invocaci贸n, entendiendo el trade-off entre una respuesta r谩pida (baja latencia) y una respuesta de alta calidad/estructurada (mayor costo y latencia).

### 5. RAG y Desaf铆o Integrador
- **Objetivo**: Construir un chatbot de soporte que responda desde una base de conocimiento local (FAQs) y devuelva un JSON estructurado.
- **T茅cnica (RAG)**: Se implement贸 un RAG b谩sico (Parte 9):
  1. **Indexaci贸n**: Se dividieron (`RecursiveCharacterTextSplitter`) y vectorizaron (`OpenAIEmbeddings`) documentos en una base `FAISS`.
  2. **Recuperaci贸n**: Se cre贸 un `retriever` para buscar los *chunks* relevantes.
- **T茅cnica (Desaf铆o)**: Se cre贸 una cadena `rag_chain_structured` que combin贸 el `retriever` (Parte 9) con el `prompt` de *grounding* (Parte 5) y la `salida estructurada` (Parte 8).

## Resultados Principales

### 1. El Peligro de `Few-Shot` + `Temperature`
El an谩lisis de la Parte 6 fue revelador. Mientras que con `T=0` los modelos *zero-shot* y *few-shot* clasificaron correctamente (POS, NEG, **NEU**), al usar `T=0.3` el modelo *few-shot* fall贸:
- Ejemplo: Texto: "Est谩 bien, nada extraordinario." -> `POS` (Incorrecto).
- El modelo *zero-shot* (con `T=0.3`) sigui贸 acertando (`NEU`).

Conclusi贸n: El *prompt* *few-shot* (que no inclu铆a ejemplos de `NEU`) cre贸 un **sesgo**. La temperatura, al permitir "creatividad", hizo que el modelo siga ese sesgo y falle, demostrando que *few-shot* mal implementado puede ser peor que *zero-shot*.

### 2. Fiabilidad del `with_structured_output`
El uso de `Pydantic` (Partes 3, 5, 8, Desaf铆o) fue 100% fiable. En lugar de devolver un `string` que podr铆a contener un JSON, el modelo devolvi贸 un objeto Python (`Resumen`, `Traduccion`, `RespuestaSoporte`).

Conclusi贸n: Esta t茅cnica es un pilar de producci贸n. Transforma al LLM de un generador de texto a un **componente de software fiable con un contrato de API (el esquema Pydantic)**.

### 3. xito del RAG y Manejo de Fallos (Desaf铆o)
El chatbot integrador demostr贸 el 茅xito del patr贸n RAG + grounding + salida estructurada:

- Caso 1 (xito RAG):
  - Pregunta: "驴Qu茅 significa la luz azul parpadeante?"
  - Respuesta: answer = "La luz azul parpadeante indica que el dispositivo est谩 buscando conexi贸n WiFi."
  - Confianza: confidence = "high"
  - El retriever encontr贸 el chunk correcto, y el LLM lo us贸 para generar la respuesta.

- Caso 2 (xito del "Fallo Controlado"):
  - Pregunta: "驴C贸mo cambio la bater铆a?"
  - Respuesta: answer = "No encontr茅 informaci贸n sobre c贸mo cambiar la bater铆a..."
  - Confianza: confidence = "low"
  - El retriever no encontr贸 contexto relevante. El LLM, obedeciendo la instrucci贸n "Respond茅 SOLO con el contexto...", **evit贸 la alucinaci贸n** y report贸 el fallo correctamente. Este es un comportamiento deseado y robusto.

## Conclusiones
- **LangChain (LCEL)** permite pasar de prompts a pipelines. El operador `|` es la herramienta clave para dise帽ar sistemas de IA complejos de forma declarativa.
- **La salida estructurada (`with_structured_output`) no es opcional para producci贸n.** Es la 煤nica forma de garantizar un "contrato de datos" fiable entre el LLM y la aplicaci贸n que lo consume, eliminando la necesidad de parsing fr谩gil.
- **RAG es el patr贸n esencial** para "aterrizar" (ground) los LLMs en conocimiento propietario.
- El prompting de un sistema RAG es cr铆tico: la instrucci贸n "Respond茅 SOLO con el contexto" es la principal defensa contra la **alucinaci贸n** cuando el conocimiento no existe en el corpus.
- La **observabilidad (`LangSmith`)** es fundamental para entender los trade-offs entre latencia (velocidad) y costo/calidad (tokens, complejidad de prompt) en cada paso de la cadena.

## Reflexi贸n Personal
Esta pr谩ctica marc贸 la transici贸n de la ingenier铆a de prompts (prompt engineering) al dise帽o de sistemas (systems design). El verdadero poder no reside solo en el LLM, sino en la **cadena de orquestaci贸n** que construimos a su alrededor. Se dise帽贸 un sistema de extremo a extremo que combina recuperaci贸n de datos (RAG) con un formato de salida garantizado (Pydantic), creando una aplicaci贸n que es fiable, observable y soluciona una necesidad de negocio concreta (chatbot de soporte).

---

##  Notebook

**[Abrir en Google Colab](https://colab.research.google.com/github/fedepds/IA-portafolio/blob/main/docs/portfolio/UT4/Practico14.ipynb)**