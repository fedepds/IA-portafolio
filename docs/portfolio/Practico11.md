
# Fine-Tuning YOLOv8 para Detecci贸n de Productos

En este proyecto traduje una necesidad organizacional (automatizaci贸n de inventario en supermercados) en una soluci贸n t茅cnica end-to-end. Demostr茅 mis habilidades en:

- **Evaluaci贸n zero-shot**: Diagn贸stico de limitaciones de modelos gen茅ricos en dominios espec铆ficos.
- **Comparativa de arquitecturas**: Experimentaci贸n controlada con YOLOv5/v8 (n, s, m) para selecci贸n informada.
- **Fine-tuning**: Transfer learning para especializar YOLO en detecci贸n de frutas.
- **Tracking en tiempo real**: Integraci贸n de YOLO + Norfair para conteo de productos en cintas.
- **An谩lisis de fallos**: Diagn贸stico sistem谩tico para definir pr贸ximas iteraciones.

Este proyecto demuestra el ciclo completo: desde la justificaci贸n de negocio hasta el despliegue y an谩lisis post-producci贸n.

## Habilidades Demostradas
- Traducir una necesidad organizacional (ej. conteo de inventario) en una soluci贸n de IA funcional.
- Evaluar el rendimiento "zero-shot" de un modelo pre-entrenado (YOLOv8n en COCO) y demostrar sus limitaciones en un dominio espec铆fico.
- Implementar un experimento de comparativa de arquitecturas (YOLOv5/v8) para seleccionar el modelo con el mejor balance de precisi贸n, velocidad y tama帽o.
- Aplicar una estrategia de fine-tuning (transfer learning) para especializar un modelo YOLO en la detecci贸n de un nuevo conjunto de clases (frutas).
- Desplegar el modelo afinado en un pipeline funcional de tracking (con Norfair) para resolver un caso de uso pr谩ctico (conteo de productos en una cinta).
- Analizar cuantitativamente el rendimiento y los fallos del sistema para definir las pr贸ximas iteraciones de mejora.

## Metodolog铆a

### 1. Diagn贸stico y Evaluaci贸n "Zero-Shot"
- **Problema**: Se parti贸 de la necesidad de un supermercado de automatizar tareas como el conteo de productos.
- **Modelo Base**: Se carg贸 un modelo `yolov8n` pre-entrenado en el dataset COCO.
- **Prueba Inicial**: Se evalu贸 el modelo en una imagen del dominio del problema (pasillo de supermercado).
- **Resultado**: La soluci贸n gen茅rica ("off-the-shelf") fracas贸. El modelo detect贸 solo 3 objetos, con clases incorrectas (ej. "orange" por "apple") y confianza muy baja (< 0.37), estableciendo la justificaci贸n de negocio para un fine-tuning personalizado.

### 2. Comparativa de Arquitecturas (Trabajo 1)
- **Objetivo**: Determinar la arquitectura con el mejor balance (trade-off) para el problema.
- **Dataset**: Se utiliz贸 un dataset de "Fruit Detection", resolviendo un problema de MLOps al reparar el archivo `data.yaml` (rutas incorrectas) para asegurar la reproducibilidad.
- **Experimento**: Se ejecut贸 un experimento controlado entrenando 5 modelos distintos (YOLOv5n, v5s, YOLOv8n, v8s, v8m).
- **Par谩metros**: El entrenamiento fue id茅ntico para todos: 10 茅pocas, `imgsz=416` y usando solo el 25% de los datos (`fraction=0.25`) para una comparativa 谩gil.
- **M茅tricas**: Se midi贸 mAP@0.5, mAP@0.5:0.95, tiempo de inferencia (ms) y tama帽o del modelo (MB).

### 3. Fine-Tuning y Evaluaci贸n (Proyecto Principal)
- **Estrategia**: Se aplic贸 transfer learning sobre el modelo `yolov8n` (seg煤n el an谩lisis principal del proyecto).
- **An谩lisis de Datos**: Se analiz贸 la distribuci贸n del dataset, detectando un desbalance de clases (muchas `Orange`, pocas `Pineapple`) para anticipar el rendimiento.
- **Entrenamiento**: Se entren贸 el modelo por 15 茅pocas usando el 100% de los datos de entrenamiento.
- **M茅tricas**: Se compar贸 el rendimiento Pre-Fine-Tuning (F1-Score de 0.0) con el Post-Fine-Tuning (F1-Score, Recall, Precisi贸n) usando el set de prueba.

### 4. Despliegue en Pipeline de Tracking
- **Caso de Uso**: Simular el conteo de productos en una cinta transportadora.
- **Herramientas**: Se integr贸 el detector YOLOv8 afinado con el tracker `Norfair`.
- **Estrategia Simbi贸tica**: Se configur贸 una estrategia de dos pasos para maximizar el rendimiento del pipeline:
    1.  **Detector (Modelo YOLO)**: Configurado con `conf=0.2` (umbral bajo) para maximizar el **Recall** (encontrarlo todo, aunque genere ruido o Falsos Positivos).
    2.  **Tracker (Norfair)**: Configurado con `initialization_delay=3` (retardo de 3 frames) para maximizar la **Precisi贸n** (filtrar el ruido y las detecciones "fantasma" moment谩neas, confiando solo en detecciones estables).

## Resultados Principales

### 1. Comparativa de Arquitecturas

El experimento de comparativa (Trabajo 1) arroj贸 un claro "punto 贸ptimo" (sweet spot).

| Modelo | mAP@0.5 | mAP@0.5:0.95 | Inferencia (ms) | Tama帽o (MB) |
|---|---:|---:|---:|---:|
| YOLOv5n | 0.336 | 0.204 | 1.8 ms | 5.2 MB |
| YOLOv5s | 0.352 | 0.221 | 3.3 ms | 18.5 MB |
| YOLOv8n | 0.357 | 0.217 | 1.8 ms | 6.2 MB |
| **YOLOv8s** | **0.400** | **0.256** | **3.7 ms** | **22.5 MB** |
| YOLOv8m | 0.375 | 0.237 | 9.2 ms | 52.0 MB |

- **An谩lisis de Trade-off**:
    - **YOLOv8s** fue el claro ganador en precisi贸n (mAP 0.400), superando a las versiones "nano" (n) con un costo de inferencia (3.7 ms) que sigue siendo trivial para el tiempo real (>270 FPS).
    - **YOLOv8m** (Medium) fue contraproducente: fue 2.5 veces m谩s lento y, sorprendentemente, *menos preciso* que `v8s`, indicando *under-fitting* (sub-entrenamiento) debido a su mayor necesidad de datos y 茅pocas.

### 2. Impacto del Fine-Tuning (Proyecto Principal)

El fine-tuning transform贸 un modelo in煤til en una soluci贸n competente.

| M茅trica | YOLOv8n Pre-entrenado (COCO) | YOLOv8n Fine-tuned (Frutas) | Mejora |
|---|---:|---:|---:|
| **F1-Score** | 0.0 | **0.800** | +Inf |
| **Recall** | ~0.0 | **1.0** | +100% |
| **Precisi贸n**| ~0.0 | **0.667** | +66.7% |

- **An谩lisis de Rendimiento**:
    - El modelo afinado demostr贸 una "personalidad" espec铆fica: un **Recall perfecto (1.0)**, indicando que es excelente para no omitir ning煤n producto.
    - Su debilidad fue una **Precisi贸n de 0.667**, lo que significa que, para lograr ese Recall, genera algunos Falsos Positivos (detecciones "fantasma"). Esta debilidad fue tratada en la siguiente etapa (Tracking).

### 3. Resultados del Pipeline de Tracking
- **xito Funcional**: El sistema funcion贸 y resolvi贸 el caso de uso. Cont贸 13 productos que pasaron por la cinta, clasific谩ndolos correctamente (5 bananas, 4 manzanas, 4 naranjas).
- **Estabilidad**: El tracking fue robusto (ej. "Track 2 - Orange" dur贸 340 de 343 frames), validando la estrategia simbi贸tica de detector+tracker.
- **Diagn贸stico de Fallos**: Se identific贸 un problema clave: la "fragmentaci贸n de IDs" en las bananas (se generaron 5 IDs de track para 2-3 bananas reales). El an谩lisis determin贸 que la causa ra铆z no era el tracker, sino el modelo (detector) que "parpadeaba" (fallaba en detectar) en ciertos frames.

## Conclusiones
- El fine-tuning no es opcional, es un paso cr铆tico. Los modelos "off-the-shelf" fallan en dominios espec铆ficos. Esta pr谩ctica demostr贸 una creaci贸n de valor medible, llevando un modelo de **0.0 a 0.800 F1-Score**.
- La selecci贸n de la arquitectura es un trade-off. El an谩lisis comparativo demostr贸 que **YOLOv8s** ofrece el "punto 贸ptimo" de precisi贸n y velocidad.
- Los modelos m谩s grandes (como `v8m`) no son inherentemente mejores y pueden rendir peor si no se les entrena con suficientes datos o 茅pocas (under-fitting).
- Un pipeline de IA (ej. Detector + Tracker) es m谩s robusto que sus componentes individuales. El tracker `Norfair` filtr贸 exitosamente los Falsos Positivos (baja Precisi贸n) del detector `YOLO`, mientras que el detector `YOLO` asegur贸 que no se omitiera ning煤n objeto (alto Recall).
- El an谩lisis de fallos (ej. "fragmentaci贸n de IDs" en bananas) es fundamental, ya que define la siguiente acci贸n estrat茅gica: no se necesita un mejor tracker, se necesitan m谩s datos de entrenamiento de bananas para mejorar el detector.

## Reflexi贸n Personal
Esta pr谩ctica ejecut贸 un proyecto de IA de extremo a extremo, reflejando perfectamente el salto de un problema de negocio a una soluci贸n t茅cnica. No nos enfocamos en inventar un nuevo algoritmo, sino en aplicar herramientas open-source (Ultralytics, Norfair) a un problema concreto. Se evaluaron las limitaciones de la herramienta base, se aplic贸 un fine-tuning para adaptarla (creando valor medible) y se la integr贸 en un pipeline funcional que resolvi贸 la necesidad organizacional. Finalmente, se analizaron las nuevas limitaciones (IDs de bananas) para definir el pr贸ximo ciclo de mejora 谩gil.

---

##  Notebook

**[Abrir en Google Colab](https://colab.research.google.com/github/fedepds/IA-portafolio/blob/main/docs/portfolio/UT3/Practico11.ipynb)**
