
# Fine-Tuning YOLOv8 para Detecci√≥n de Productos

En este proyecto traduje una necesidad organizacional (automatizaci√≥n de inventario en supermercados) en una soluci√≥n t√©cnica end-to-end. Demostr√© mis habilidades en:

- **Evaluaci√≥n zero-shot**: Diagn√≥stico de limitaciones de modelos gen√©ricos en dominios espec√≠ficos.
- **Comparativa de arquitecturas**: Experimentaci√≥n controlada con YOLOv5/v8 (n, s, m) para selecci√≥n informada.
- **Fine-tuning**: Transfer learning para especializar YOLO en detecci√≥n de frutas.
- **Tracking en tiempo real**: Integraci√≥n de YOLO + Norfair para conteo de productos en cintas.
- **An√°lisis de fallos**: Diagn√≥stico sistem√°tico para definir pr√≥ximas iteraciones.

Este proyecto demuestra el ciclo completo: desde la justificaci√≥n de negocio hasta el despliegue y an√°lisis post-producci√≥n.

---

## üöÄ Valor Agregado e Innovaci√≥n

Este proyecto va m√°s all√° de un ejercicio acad√©mico t√≠pico, demostrando habilidades de ingenier√≠a de producci√≥n:

### 1. Experimentaci√≥n Sistem√°tica y Selecci√≥n Fundamentada
- **No me limit√© al modelo base**: Compar√© 6 arquitecturas (YOLOv5n/s, YOLOv8n/s/m) documentando trade-offs cuantitativos de precisi√≥n/velocidad/tama√±o.
- **Resultado**: Identific√© que YOLOv8s ofrece el "punto √≥ptimo" (mAP 0.400, 3.7ms inferencia), mientras que v8m fue contraproducente (m√°s lento y menos preciso por under-fitting).
- **Aprendizaje**: Este tipo de benchmarking es importante cuando los recursos de c√≥mputo tienen un costo real.

### 2. Pipeline Completo

- **Integraci√≥n detector + tracker**: No solo fine-tune√© un modelo, sino que lo integr√© en un pipeline funcional (YOLO + Norfair) que simula un sistema real de inventario automatizado.
- **Dise√±o de arquitectura balanceada**: 
  - Detector configurado con `conf=0.2` (alto Recall, acepta ruido)
  - Tracker configurado con `initialization_delay=3` (alta Precision, filtra ruido)
- **Aprendizaje**: Vi c√≥mo subsistemas complementarios se balancean mutuamente en un sistema real.

### 3. An√°lisis de Fallos Estructurado (Root Cause Analysis)

- **Problema observado**: Fragmentaci√≥n de IDs en bananas (5 IDs para 2-3 objetos reales)
- **Diagn√≥stico metod√≥logico**: Aisl√© componentes del pipeline para identificar la causa ra√≠z
- **Conclusi√≥n**: El problema NO era el tracker (Norfair), sino el detector (YOLO "parpadeaba" perdiendo detecciones en frames intermedios)
- **Aprendizaje**: Esta forma de debugging sistem√°tico es esencial para entender qu√© est√° fallando en un sistema complejo.

### 4. Traducci√≥n T√©cnica-Pr√°ctica

- **M√©tricas t√©cnicas ‚Üí Impacto real**: Traduje F1-Score (0.0 ‚Üí 0.800) a "automatizaci√≥n viable de conteo de inventario"
- **Justificaci√≥n de fine-tuning**: Mostr√© cuantitativamente por qu√© los modelos gen√©ricos fallan en dominios espec√≠ficos (COCO no tiene "banana" como clase)
- **Aprendizaje**: Es importante poder explicar el valor t√©cnico en t√©rminos pr√°cticos.

### 5. Ciclo de Mejora Continua

- **Identificaci√≥n de siguiente iteraci√≥n**: Basado en el an√°lisis de fallos, propuse aumentar el dataset de entrenamiento y aplicar data augmentation espec√≠fico para bananas
- **Aprendizaje**: Aprend√≠ a pensar en mejora iterativa, no solo en "entregar y terminar".

---

## Habilidades Demostradas

- Traducir una necesidad pr√°ctica (ej. conteo de inventario) en una soluci√≥n de IA funcional.
- Evaluar el rendimiento "zero-shot" de un modelo pre-entrenado (YOLOv8n en COCO) y mostrar sus limitaciones en un dominio espec√≠fico.
- Implementar un experimento de comparativa de arquitecturas (YOLOv5/v8) para elegir el modelo con el mejor balance de precision, velocidad y tama√±o.
- Aplicar fine-tuning (transfer learning) para especializar un modelo YOLO en la detecci√≥n de nuevas clases (frutas).
- Desplegar el modelo en un pipeline funcional de tracking (con Norfair) para resolver un caso de uso pr√°ctico (conteo de productos en una cinta).
- Analizar cuantitativamente el rendimiento y los fallos del sistema para definir las pr√≥ximas mejoras.

## Metodolog√≠a

### 1. Diagn√≥stico y Evaluaci√≥n "Zero-Shot"

- **Problema**: Part√≠ de la necesidad de automatizar tareas como el conteo de productos en un supermercado.
- **Modelo Base**: Cargu√© un modelo `yolov8n` pre-entrenado en el dataset COCO.
- **Prueba Inicial**: Se evalu√≥ el modelo en una imagen del dominio del problema (pasillo de supermercado).
- **Resultado**: La soluci√≥n gen√©rica ("off-the-shelf") fracas√≥. El modelo detect√≥ solo 3 objetos, con clases incorrectas (ej. "orange" por "apple") y confianza muy baja (< 0.37), estableciendo la justificaci√≥n de negocio para un fine-tuning personalizado.

### 2. Comparativa de Arquitecturas (Trabajo 1)
- **Objetivo**: Determinar la arquitectura con el mejor balance (trade-off) para el problema.
- **Dataset**: Se utiliz√≥ un dataset de "Fruit Detection", resolviendo un problema de MLOps al reparar el archivo `data.yaml` (rutas incorrectas) para asegurar la reproducibilidad.
- **Experimento**: Se ejecut√≥ un experimento controlado entrenando 5 modelos distintos (YOLOv5n, v5s, YOLOv8n, v8s, v8m).
- **Par√°metros**: El entrenamiento fue id√©ntico para todos: 10 √©pocas, `imgsz=416` y usando solo el 25% de los datos (`fraction=0.25`) para una comparativa √°gil.
- **M√©tricas**: Se midi√≥ mAP@0.5, mAP@0.5:0.95, tiempo de inferencia (ms) y tama√±o del modelo (MB).

### 3. Fine-Tuning y Evaluaci√≥n (Proyecto Principal)
- **Estrategia**: Se aplic√≥ transfer learning sobre el modelo `yolov8n` (seg√∫n el an√°lisis principal del proyecto).
- **An√°lisis de Datos**: Se analiz√≥ la distribuci√≥n del dataset, detectando un desbalance de clases (muchas `Orange`, pocas `Pineapple`) para anticipar el rendimiento.
- **Entrenamiento**: Se entren√≥ el modelo por 15 √©pocas usando el 100% de los datos de entrenamiento.
- **M√©tricas**: Se compar√≥ el rendimiento Pre-Fine-Tuning (F1-Score de 0.0) con el Post-Fine-Tuning (F1-Score, Recall, Precision) usando el set de prueba.

### 4. Despliegue en Pipeline de Tracking
- **Caso de Uso**: Simular el conteo de productos en una cinta transportadora.
- **Herramientas**: Se integr√≥ el detector YOLOv8 afinado con el tracker `Norfair`.
- **Estrategia Simbi√≥tica**: Se configur√≥ una estrategia de dos pasos para maximizar el rendimiento del pipeline:
    1.  **Detector (Modelo YOLO)**: Configurado con `conf=0.2` (umbral bajo) para maximizar el **Recall** (encontrarlo todo, aunque genere ruido o Falsos Positivos).
    2.  **Tracker (Norfair)**: Configurado con `initialization_delay=3` (retardo de 3 frames) para maximizar la **Precision** (filtrar el ruido y las detecciones "fantasma" moment√°neas, confiando solo en detecciones estables).

## Resultados Principales

### 1. Comparativa de Arquitecturas

El experimento de comparativa (Trabajo 1) arroj√≥ un claro "punto √≥ptimo" (sweet spot).

| Modelo | mAP@0.5 | mAP@0.5:0.95 | Inferencia (ms) | Tama√±o (MB) |
|---|---:|---:|---:|---:|
| YOLOv5n | 0.336 | 0.204 | 1.8 ms | 5.2 MB |
| YOLOv5s | 0.352 | 0.221 | 3.3 ms | 18.5 MB |
| YOLOv8n | 0.357 | 0.217 | 1.8 ms | 6.2 MB |
| **YOLOv8s** | **0.400** | **0.256** | **3.7 ms** | **22.5 MB** |
| YOLOv8m | 0.375 | 0.237 | 9.2 ms | 52.0 MB |

- **An√°lisis de Trade-off**:
    - **YOLOv8s** fue el claro ganador en precision (mAP 0.400), superando a las versiones "nano" (n) con un costo de inferencia (3.7 ms) que sigue siendo trivial para el tiempo real (>270 FPS).
    - **YOLOv8m** (Medium) fue contraproducente: fue 2.5 veces m√°s lento y, sorprendentemente, *menos precise* que `v8s`, indicando *under-fitting* (sub-entrenamiento) debido a su mayor necesidad de datos y epochs.

### 2. Impacto del Fine-Tuning (Proyecto Principal)

El fine-tuning transform√≥ un modelo in√∫til en una soluci√≥n competente.

| M√©trica | YOLOv8n Pre-entrenado (COCO) | YOLOv8n Fine-tuned (Frutas) | Mejora |
|---|---:|---:|---:|
| **F1-Score** | 0.0 | **0.800** | +Inf |
| **Recall** | ~0.0 | **1.0** | +100% |
| **Precision**| ~0.0 | **0.667** | +66.7% |

- **An√°lisis de Rendimiento**:
    - El modelo afinado demostr√≥ una "personalidad" espec√≠fica: un **Recall perfecto (1.0)**, indicando que es excelente para no omitir ning√∫n producto.
    - Su debilidad fue una **Precision de 0.667**, lo que significa que, para lograr ese Recall, genera algunos Falsos Positivos (detecciones "fantasma"). Esta debilidad fue tratada en la siguiente etapa (Tracking).

### 3. Resultados del Pipeline de Tracking
- **√âxito Funcional**: El sistema funcion√≥ y resolvi√≥ el caso de uso. Cont√≥ 13 productos que pasaron por la cinta, clasific√°ndolos correctamente (5 bananas, 4 manzanas, 4 naranjas).
- **Estabilidad**: El tracking fue robusto (ej. "Track 2 - Orange" dur√≥ 340 de 343 frames), validando la estrategia simbi√≥tica de detector+tracker.
- **Diagn√≥stico de Fallos**: Se identific√≥ un problema clave: la "fragmentaci√≥n de IDs" en las bananas (se generaron 5 IDs de track para 2-3 bananas reales). El an√°lisis determin√≥ que la causa ra√≠z no era el tracker, sino el modelo (detector) que "parpadeaba" (fallaba en detectar) en ciertos frames.

## Conclusiones
- El fine-tuning no es opcional, es un paso cr√≠tico. Los modelos "off-the-shelf" fallan en dominios espec√≠ficos. Esta pr√°ctica demostr√≥ una creaci√≥n de valor medible, llevando un modelo de **0.0 a 0.800 F1-Score**.
- La selecci√≥n de la arquitectura es un trade-off. El an√°lisis comparativo demostr√≥ que **YOLOv8s** ofrece el "punto √≥ptimo" de precision y velocidad.
- Los modelos m√°s grandes (como `v8m`) no son inherentemente mejores y pueden rendir peor si no se les entrena con suficientes datos o √©pocas (under-fitting).
- Un pipeline de IA (ej. Detector + Tracker) es m√°s robusto que sus componentes individuales. El tracker `Norfair` filtr√≥ exitosamente los Falsos Positivos (baja Precision) del detector `YOLO`, mientras que el detector `YOLO` asegur√≥ que no se omitiera ning√∫n objeto (alto Recall).
- El an√°lisis de fallos (ej. "fragmentaci√≥n de IDs" en bananas) es fundamental, ya que define la siguiente acci√≥n estrat√©gica: no se necesita un mejor tracker, se necesitan m√°s datos de entrenamiento de bananas para mejorar el detector.

## Reflexi√≥n Personal
Esta pr√°ctica ejecut√≥ un proyecto de IA de extremo a extremo, reflejando perfectamente el salto de un problema de negocio a una soluci√≥n t√©cnica. No nos enfocamos en inventar un nuevo algoritmo, sino en aplicar herramientas open-source (Ultralytics, Norfair) a un problema concreto. Se evaluaron las limitaciones de la herramienta base, se aplic√≥ un fine-tuning para adaptarla (creando valor medible) y se la integr√≥ en un pipeline funcional que resolvi√≥ la necesidad organizacional. Finalmente, se analizaron las nuevas limitaciones (IDs de bananas) para definir el pr√≥ximo ciclo de mejora √°gil.

---

## üìì Notebook

**[Abrir en Google Colab](https://colab.research.google.com/github/fedepds/IA-portafolio/blob/main/docs/portfolio/UT3/Practico11.ipynb)**
