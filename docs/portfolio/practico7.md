# Fundamentos de Redes Neuronales (MLP)
**Unidad 2 ‚Äì Fundamentos de Deep Learning**

---

## üìò Descripci√≥n

En este proyecto profundic√© en los fundamentos del **Deep Learning**, implementando **redes neuronales artificiales (MLPs)** desde cero. Demostr√© mi dominio de:

- Arquitecturas neuronales: desde perceptrones simples hasta redes multicapa complejas.
- T√©cnicas de regularizaci√≥n (Dropout) para prevenir overfitting.
- Optimizaci√≥n de hiperpar√°metros: funciones de activaci√≥n, optimizadores y configuraciones de capas.
- Evaluaci√≥n sistem√°tica del rendimiento con m√©tricas de clasificaci√≥n.

Implement√© experimentos controlados para analizar c√≥mo cada componente impacta en la convergencia, precisi√≥n y capacidad de generalizaci√≥n.

---

## üéØ Habilidades Demostradas

- Comprender la estructura y funcionamiento de un **perceptr√≥n artificial**.  
- Implementar redes neuronales **multicapa (MLP)** utilizando *Keras* y *TensorFlow*.  
- Explorar **diferentes funciones de activaci√≥n** (`relu`, `tanh`, `logistic`).  
- Comparar **optimizadores** (`adam`, `sgd`, `rmsprop`) y su efecto sobre la convergencia.  
- Aplicar **regularizaci√≥n** mediante `Dropout` para prevenir el overfitting.  
- Evaluar el desempe√±o de las redes con **m√©tricas de clasificaci√≥n** (accuracy, precision, recall, F1-score).  
- Analizar la **estabilidad y capacidad de generalizaci√≥n** de cada configuraci√≥n.

---

## üìä Dataset

Se emplearon datasets cl√°sicos para tareas de clasificaci√≥n supervisada, entre ellos:

- **XOR dataset** (problema no lineal, ideal para observar limitaciones del perceptr√≥n).  
- **Datasets de referencia de Scikit-Learn**, como *Breast Cancer* o *Digits*, para probar distintas arquitecturas MLP.  

Las variables de entrada fueron normalizadas para asegurar un entrenamiento estable, siguiendo las recomendaciones vistas en clase.

---

## ‚öôÔ∏è Desarrollo

El flujo de trabajo sigui√≥ el **pipeline est√°ndar de Deep Learning**:

1. **Configuraci√≥n del entorno TensorFlow / Keras**  
   - Inicializaci√≥n del entorno con control de GPU y seeds de reproducibilidad.  

2. **Dise√±o de modelos**  
   - üîπ *Perceptr√≥n simple:* red de una sola capa lineal, probada sobre el problema XOR.  
   - üîπ *MLP multicapa:* se experiment√≥ con arquitecturas `(4,)`, `(10,)`, `(4,4)`, `(10,5)` y `(64,32,16)`.

3. **Funciones de activaci√≥n**  
   - Comparaci√≥n entre `relu`, `tanh` y `logistic`, observando efectos sobre la convergencia y la capacidad de aprendizaje.

4. **Regularizaci√≥n**  
   - Incorporaci√≥n de **Dropout** (0.2‚Äì0.5) para evitar overfitting y mejorar la robustez del modelo.

5. **Optimizaci√≥n**  
   - Se testearon distintos **optimizadores** (`adam`, `sgd`, `rmsprop`), ajustando el *learning rate* y par√°metros de momentum.

6. **Entrenamiento y validaci√≥n**  
   - Divisi√≥n de datos en *train/test*.  
   - Monitoreo de la p√©rdida y accuracy por √©poca.  
   - Evaluaci√≥n con m√©tricas de rendimiento.

7. **Visualizaci√≥n y an√°lisis**  
   - Gr√°ficas de p√©rdida y accuracy.  
   - Reportes de clasificaci√≥n y comparaci√≥n de resultados.

---

## üìà Resultados

- El **perceptr√≥n simple** no logr√≥ resolver el problema XOR, confirmando su limitaci√≥n para separar clases no lineales.  
- Las **redes multicapa (MLP)** s√≠ aprendieron correctamente la frontera de decisi√≥n, evidenciando la importancia de la **no linealidad y profundidad**.  
- **Funciones de activaci√≥n:**  
  - `relu` ofreci√≥ la mejor convergencia y desempe√±o general.  
  - `tanh` mostr√≥ estabilidad pero menor velocidad.  
  - `logistic` tuvo problemas de saturaci√≥n y gradientes peque√±os.  
- **Optimizadores:**  
  - `adam` alcanz√≥ los mejores resultados con m√≠nima configuraci√≥n.  
  - `sgd` fue m√°s estable pero requiri√≥ mayor tuning.  
  - `rmsprop` funcion√≥ bien con tasas de aprendizaje peque√±as.  
- **Dropout** (0.3‚Äì0.5) ayud√≥ a mejorar la generalizaci√≥n reduciendo el sobreajuste.  

üìä *El modelo final alcanz√≥ una accuracy promedio superior al 95% en los datasets utilizados.*

---

## üß© Conclusiones

- Las **redes neuronales multicapa** permiten modelar relaciones complejas que los modelos lineales no pueden capturar.  
- La elecci√≥n de **arquitectura, activaci√≥n y optimizador** influye directamente en la capacidad de aprendizaje y estabilidad del modelo.  
- El **Dropout** y otras formas de regularizaci√≥n son esenciales para evitar el sobreajuste y mejorar la robustez del aprendizaje.  
- Este pr√°ctico consolida la comprensi√≥n de los principios fundamentales de **Deep Learning**, sentando las bases para avanzar hacia arquitecturas m√°s complejas como las **CNNs** y el **Transfer Learning** en la siguiente unidad.

---

## üîó Referencias

- Kurucz, J. F. ‚Äì *Fundamentos del Aprendizaje Autom√°tico*, Unidad 2 (Deep Learning).  
- **TensorFlow / Keras API Docs:**  
  [https://www.tensorflow.org/api_docs/python/tf/keras](https://www.tensorflow.org/api_docs/python/tf/keras)  
- **Scikit-learn documentation:**  
  [https://scikit-learn.org/](https://scikit-learn.org/)  
- Goodfellow, I., Bengio, Y., & Courville, A. ‚Äì *Deep Learning* (MIT Press, 2016)

---

## üìì Notebook

[Ver Notebook Completo](UT2/practico7.ipynb)