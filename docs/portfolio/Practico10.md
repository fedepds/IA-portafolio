# Data Augmentation y XAI con Transfer Learning (Flowers102)

En este proyecto apliqu√© **Transfer Learning** a un problema complejo de clasificaci√≥n (102 especies de flores), integrando t√©cnicas avanzadas:

- **Data Augmentation**: Pipeline robusto con transformaciones m√∫ltiples para simular variabilidad real.
- **Transfer Learning**: Fine-tuning de EfficientNetB0 pre-entrenado en ImageNet.
- **Explicabilidad (XAI)**: Implementaci√≥n de GradCAM e Integrated Gradients para auditar decisiones del modelo.
- **Diagn√≥stico de overfitting**: An√°lisis de curvas de entrenamiento y propuestas de mejora.

Demostr√© que la explicabilidad no es un "extra" sino una herramienta cr√≠tica de debugging y confianza en producci√≥n.

--- a un dataset complejo (Flowers102), enfoc√°ndonos en robustez (Data Augmentation) y confianza (Explicabilidad: GradCAM e Integrated Gradients).

## Objetivos
- Aplicar Transfer Learning (EfficientNetB0) para clasificaci√≥n de 102 clases.
- Implementar pipeline de Data Augmentation para simular variaciones de captura.
- Diagnosticar sobreajuste analizando curvas de entrenamiento.
- Implementar GradCAM e Integrated Gradients para auditar decisiones del modelo.
- Usar XAI como herramienta de diagn√≥stico de errores.

## Metodolog√≠a

### Preprocesamiento
- Carga de oxford_flowers102 con TFDS.
- Subset usado para iteraci√≥n r√°pida (~5k train, 1k test).
- Redimensionado a 224√ó224 y normalizaci√≥n de EfficientNet.

### Arquitectura (Transfer Learning)
- Base: EfficientNetB0 preentrenado en ImageNet.
- Fine-tuning (base_model.trainable = True).
- Cabezal: GlobalAveragePooling2D + Dense(102, activation='softmax').

### Pipeline de Augmentation
- Capas Keras: RandomFlip, RandomRotation (0.125), RandomZoom (0.2),
  RandomTranslation (0.2), RandomBrightness (0.2), RandomContrast (0.2).

### Entrenamiento y Evaluaci√≥n
- Optimizador: Adam.
- Loss: sparse_categorical_crossentropy.
- Entrenamiento: 10 √©pocas sobre el subset.
- Monitoreo de train/val loss y accuracy.

### An√°lisis de Explicabilidad (XAI)
- GradCAM aplicado sobre la capa de convoluci√≥n superior (top_conv).
- Integrated Gradients para atribuciones m√°s detalladas.
- Evaluaci√≥n de predicciones correctas e incorrectas para diagn√≥stico.

## Resultados principales
- Rendimiento: val_accuracy m√°ximo ~81.5% (√©poca 6); test_accuracy final ~78.8%.
- Sobreajuste: train_accuracy ~98.2% vs val_accuracy ~78.8% (brecha ~20 puntos).
- val_loss toc√≥ m√≠nimo en √©poca 6 (‚âà0.7544) y luego aument√≥, indicando sobreajuste.
- GradCAM: en aciertos la atenci√≥n se centra en la flor.
- Integrated Gradients: atribuciones m√°s finas en estambres y partes relevantes.
- Diagn√≥stico de errores: adaptaci√≥n de GradCAM para auditar por qu√© falla (fondo, confusiones entre especies similares).

## Conclusiones
- Transfer Learning (EfficientNetB0) es efectivo para problemas de visi√≥n con muchas clases.
- Data Augmentation b√°sico ayuda, pero no evita el overfitting en entrenamiento limitado.
- T√©cnicas avanzadas (Mixup/CutMix, regularizaci√≥n) recomendadas para mejorar generalizaci√≥n.
- XAI (GradCAM/IG) es esencial para confiar y depurar modelos en contextos reales.

## Reflexi√≥n personal
- Aprendizaje pr√°ctico sobre la importancia de logs y visualizaciones m√°s all√° del accuracy.
- GradCAM demostr√≥ ser una herramienta de debugging crucial.
- Este ejercicio muestra la diferencia entre "modelo que funciona" y "modelo en el que podemos confiar".

## Pr√≥ximo paso
- Implementar ModelCheckpoint para guardar el mejor modelo (√©poca 6).
- Probar Mixup/CutMix y regularizaci√≥n adicional para reducir overfitting.

---

## üìì Notebook

**[Abrir en Google Colab](https://colab.research.google.com/github/fedepds/IA-portafolio/blob/main/docs/portfolio/UT3/Practico10.ipynb)**