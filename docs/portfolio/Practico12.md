# Fine-Tuning de SAM para Segmentaci贸n de Inundaciones

En este proyecto apliqu茅 **fine-tuning de un modelo de fundaci贸n** (Segment Anything Model - SAM) para un problema cr铆tico: detecci贸n de 谩reas inundadas en im谩genes satelitales. Demostr茅:

- **Transfer learning eficiente**: Fine-tuning selectivo del decoder (4.33% de par谩metros) logrando mejoras significativas.
- **Evaluaci贸n zero-shot**: An谩lisis del rendimiento base con prompts de punto y caja.
- **Comparaci贸n arquitect贸nica**: Benchmarking contra U-Net especialista para validar la estrategia.
- **M茅tricas de segmentaci贸n**: IoU, Dice, Precisi贸n y Recall para evaluaci贸n exhaustiva.

Este proyecto muestra c贸mo adaptar modelos generalistas de gran escala a dominios espec铆ficos con eficiencia computacional.

## Habilidades Demostradas
- Aplicar un modelo de fundaci贸n (SAM) a un dominio de segmentaci贸n novedoso.
- Evaluar el rendimiento "zero-shot" de SAM usando prompts de punto y caja.
- Implementar una estrategia de fine-tuning eficiente, entrenando 煤nicamente el decodificador de m谩scaras de SAM.
- Comparar cuantitativamente (IoU, Dice) el rendimiento del modelo pre-entrenado vs. el afinado.
- Entrenar un modelo especialista (U-Net con backbone ResNet34) como baseline competitivo.
- Analizar las ventajas y desventajas entre un modelo generalista afinado (SAM) y un especialista entrenado desde cero (U-Net).

## Metodolog铆a

### 1. Preparaci贸n y An谩lisis del Dataset
- **Dataset**: Se utiliz贸 el "Flood Area Segmentation" de Kaggle, que contiene im谩genes satelitales y sus correspondientes m谩scaras binarias indicando la presencia de agua.
- **Carga y Exploraci贸n**: Se cargaron 100 muestras, analizando la estructura de directorios y visualizando pares de imagen/m谩scara para entender la tarea.

### 2. Evaluaci贸n Zero-Shot de SAM
- **Modelo**: Se carg贸 el modelo `sam_vit_b_01ec64.pth`.
- **Prompts**: Se evalu贸 el rendimiento del modelo pre-entrenado sin ning煤n tipo de fine-tuning, utilizando dos tipos de prompts generados a partir de las m谩scaras de verdad (`ground truth`):
    - **Point Prompt**: Un 煤nico punto en el centro de la regi贸n de agua.
    - **Box Prompt**: Un cuadro delimitador (`bounding box`) que encierra toda la regi贸n de agua.
- **M茅tricas**: Se midi贸 el rendimiento inicial usando IoU, Dice, Precisi贸n y Recall.

### 3. Fine-tuning de SAM
- **Estrategia**: Se aplic贸 una t茅cnica de fine-tuning eficiente (Parameter-Efficient Fine-Tuning, PEFT):
    - **Congelado**: Se congelaron los pesos del `image_encoder` y `prompt_encoder`, que son la mayor parte del modelo.
    - **Entrenamiento**: Se entren贸 煤nicamente el `mask_decoder`, que representa menos del 5% de los par谩metros totales.
- **Dataset**: Se cre贸 un `torch.utils.data.Dataset` que redimensiona las im谩genes a 1024x1024 (tama帽o nativo de SAM) y genera `point prompts` aleatorios dentro de las 谩reas de agua para cada muestra.
- **Loss Function**: Se utiliz贸 una p茅rdida combinada de `Binary Cross-Entropy (BCE)` y `Dice Loss` para un entrenamiento m谩s estable.
- **Entrenamiento**: Se entren贸 el modelo durante 17 茅pocas con un `batch size` peque帽o (2) debido al alto consumo de memoria de SAM.

### 4. Entrenamiento del Modelo U-Net
- **Arquitectura**: Como comparativa, se implement贸 un modelo `U-Net` con un backbone `ResNet34` pre-entrenado en ImageNet, utilizando la librer铆a `segmentation-models-pytorch`.
- **Entrenamiento**: Se entren贸 el modelo completo sobre el mismo dataset, pero con im谩genes redimensionadas a 256x256, lo que permiti贸 un `batch size` mucho mayor (16).

## Resultados Principales

| M茅trica      | SAM Pre-entrenado (Point) | SAM Fine-tuned (Point) | Mejora (%) | U-Net (ResNet34) |
|--------------|---------------------------|------------------------|------------|------------------|
| **Mean IoU** | 0.7389                    | **0.8911**             | +20.59%    | **0.9084**       |
| **Mean Dice**| 0.8183                    | **0.9348**             | +14.24%    | **0.9501**       |

- **Rendimiento Base**: El modelo SAM pre-entrenado ya mostraba una capacidad de segmentaci贸n decente (IoU ~0.74), pero fallaba en casos complejos o con 谩reas de agua delgadas.
- **Impacto del Fine-tuning**: El fine-tuning del decodificador mejor贸 dr谩sticamente el rendimiento, aumentando el IoU medio en m谩s de 20 puntos porcentuales. El modelo afinado demostr贸 ser mucho m谩s preciso y robusto para el dominio espec铆fico de inundaciones.
- **Comparaci贸n con U-Net**: El modelo U-Net, un especialista entrenado de extremo a extremo, alcanz贸 el mejor rendimiento general (IoU ~0.91), superando ligeramente al SAM afinado.

## Conclusiones
- El fine-tuning es una estrategia extremadamente efectiva para adaptar modelos de fundaci贸n como SAM a tareas espec铆ficas, logrando mejoras significativas con un coste computacional reducido (solo se entren贸 el 4.33% de los par谩metros).
- SAM afinado se convierte en un segmentador de alto rendimiento, cerrando en gran medida la brecha con arquitecturas especialistas como U-Net.
- Existe un trade-off:
    - **U-Net**: Ofrece el m谩ximo rendimiento pero requiere un entrenamiento completo y es un modelo "especialista" que solo sirve para esta tarea.
    - **SAM Fine-tuned**: Logra un rendimiento casi a la par, manteniendo la flexibilidad de la arquitectura original y requiriendo un entrenamiento mucho m谩s eficiente.

## Reflexi贸n Personal
Esta pr谩ctica demuestra el poder de los modelos de fundaci贸n y el paradigma de "pre-entrenar y luego afinar". En lugar de construir un modelo desde cero, podemos tomar un modelo generalista y, con un esfuerzo computacional relativamente bajo, especializarlo para que sobresalga en una tarea concreta. La comparaci贸n con U-Net subraya que, si bien los modelos especialistas a煤n pueden tener una ligera ventaja, los modelos de fundaci贸n afinados son una alternativa incre铆blemente potente y eficiente.

---

##  Notebook

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fedepds/IA-portafolio/blob/main/docs/portfolio/UT3/Practico12.ipynb)

[Ver Notebook en GitHub](UT3/Practico12.ipynb)