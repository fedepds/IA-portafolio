# Fine-Tuning de SAM para Segmentaci칩n de Inundaciones

En este proyecto apliqu칠 **fine-tuning de un modelo de fundaci칩n** (Segment Anything Model - SAM) para un problema cr칤tico: detecci칩n de 치reas inundadas en im치genes satelitales. Demostr칠:

- **Transfer learning eficiente**: Fine-tuning selectivo del decoder (4.33% de par치metros) logrando mejoras significativas.
- **Evaluaci칩n zero-shot**: An치lisis del rendimiento base con prompts de punto y caja.
- **Comparaci칩n arquitect칩nica**: Benchmarking contra U-Net especialista para validar la estrategia.
- **M칠tricas de segmentaci칩n**: IoU, Dice, Precision y Recall para evaluaci칩n exhaustiva.

Este proyecto muestra c칩mo adaptar modelos generalistas de gran escala a dominios espec칤ficos con eficiencia computacional.

## Habilidades Demostradas
- Aplicar un modelo de fundaci칩n (SAM) a un dominio de segmentaci칩n novedoso.
- Evaluar el rendimiento "zero-shot" de SAM usando prompts de punto y caja.
- Implementar una estrategia de fine-tuning eficiente, entrenando 칰nicamente el decodificador de m치scaras de SAM.
- Comparar cuantitativamente (IoU, Dice) el rendimiento del modelo pre-entrenado vs. el afinado.
- Entrenar un modelo especialista (U-Net con backbone ResNet34) como baseline competitivo.
- Analizar las ventajas y desventajas entre un modelo generalista afinado (SAM) y un especialista entrenado desde cero (U-Net).

## Metodolog칤a

### 1. Preparaci칩n y An치lisis del Dataset
- **Dataset**: Se utiliz칩 el "Flood Area Segmentation" de Kaggle, que contiene im치genes satelitales y sus correspondientes m치scaras binarias indicando la presencia de agua.
- **Carga y Exploraci칩n**: Se cargaron 100 muestras, analizando la estructura de directorios y visualizando pares de imagen/m치scara para entender la tarea.

### 2. Evaluaci칩n Zero-Shot de SAM
- **Modelo**: Se carg칩 el modelo `sam_vit_b_01ec64.pth`.
- **Prompts**: Se evalu칩 el rendimiento del modelo pre-entrenado sin ning칰n tipo de fine-tuning, utilizando dos tipos de prompts generados a partir de las m치scaras de verdad (`ground truth`):
    - **Point Prompt**: Un 칰nico punto en el centro de la regi칩n de agua.
    - **Box Prompt**: Un cuadro delimitador (`bounding box`) que encierra toda la regi칩n de agua.
- **M칠tricas**: Se midi칩 el rendimiento inicial usando IoU, Dice, Precision y Recall.

### 3. Fine-tuning de SAM
- **Estrategia**: Se aplic칩 una t칠cnica de fine-tuning eficiente (Parameter-Efficient Fine-Tuning, PEFT):
    - **Congelado**: Se congelaron los pesos del `image_encoder` y `prompt_encoder`, que son la mayor parte del modelo.
    - **Entrenamiento**: Se entren칩 칰nicamente el `mask_decoder`, que representa menos del 5% de los par치metros totales.
- **Dataset**: Se cre칩 un `torch.utils.data.Dataset` que redimensiona las im치genes a 1024x1024 (tama침o nativo de SAM) y genera `point prompts` aleatorios dentro de las 치reas de agua para cada muestra.
- **Loss Function**: Se utiliz칩 una p칠rdida combinada de `Binary Cross-Entropy (BCE)` y `Dice Loss` para un entrenamiento m치s estable.
- **Entrenamiento**: Se entren칩 el modelo durante 17 epochs con un `batch size` peque침o (2) debido al alto consumo de memoria de SAM.

### 4. Entrenamiento del Modelo U-Net
- **Arquitectura**: Como comparativa, se implement칩 un modelo `U-Net` con un backbone `ResNet34` pre-entrenado en ImageNet, utilizando la librer칤a `segmentation-models-pytorch`.
- **Entrenamiento**: Se entren칩 el modelo completo sobre el mismo dataset, pero con im치genes redimensionadas a 256x256, lo que permiti칩 un `batch size` mucho mayor (16).

## Resultados Principales

| M칠trica      | SAM Pre-entrenado (Point) | SAM Fine-tuned (Point) | Mejora (%) | U-Net (ResNet34) |
|--------------|---------------------------|------------------------|------------|------------------|
| **Mean IoU** | 0.7389                    | **0.8911**             | +20.59%    | **0.9084**       |
| **Mean Dice**| 0.8183                    | **0.9348**             | +14.24%    | **0.9501**       |

- **Rendimiento Base**: El modelo SAM pre-entrenado ya mostraba una capacidad de segmentaci칩n decente (IoU ~0.74), pero fallaba en casos complejos o con 치reas de agua delgadas.
- **Impacto del Fine-tuning**: El fine-tuning del decodificador mejor칩 dr치sticamente el rendimiento, aumentando el IoU medio en m치s de 20 puntos porcentuales. El modelo afinado demostr칩 ser mucho m치s preciso y robusto para el dominio espec칤fico de inundaciones.
- **Comparaci칩n con U-Net**: El modelo U-Net, un especialista entrenado de extremo a extremo, alcanz칩 el mejor rendimiento general (IoU ~0.91), superando ligeramente al SAM afinado.

## Conclusiones
- El fine-tuning es una estrategia extremadamente efectiva para adaptar modelos de fundaci칩n como SAM a tareas espec칤ficas, logrando mejoras significativas con un coste computacional reducido (solo se entren칩 el 4.33% de los par치metros).
- SAM afinado se convierte en un segmentador de alto rendimiento, cerrando en gran medida la brecha con arquitecturas especialistas como U-Net.
- Existe un trade-off:
    - **U-Net**: Ofrece el m치ximo rendimiento pero requiere un entrenamiento completo y es un modelo "especialista" que solo sirve para esta tarea.
    - **SAM Fine-tuned**: Logra un rendimiento casi a la par, manteniendo la flexibilidad de la arquitectura original y requiriendo un entrenamiento mucho m치s eficiente.

## Reflexi칩n Personal
Esta pr치ctica demuestra el poder de los modelos de fundaci칩n y el paradigma de "pre-entrenar y luego afinar". En lugar de construir un modelo desde cero, podemos tomar un modelo generalista y, con un esfuerzo computacional relativamente bajo, especializarlo para que sobresalga en una tarea concreta. La comparaci칩n con U-Net subraya que, si bien los modelos especialistas a칰n pueden tener una ligera ventaja, los modelos de fundaci칩n afinados son una alternativa incre칤blemente potente y eficiente.

---

## 游늽 Notebook

**[Abrir en Google Colab](https://colab.research.google.com/github/fedepds/IA-portafolio/blob/main/docs/portfolio/UT3/Practico12.ipynb)**